# Implementation Plan: RAG Chatbot Integration

**Branch**: `005-rag-chatbot-integration` | **Date**: 2025-12-29 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `/specs/005-rag-chatbot-integration/spec.md`

## Summary

Implement an integrated RAG (Retrieval-Augmented Generation) chatbot for the Physical AI & Humanoid Robotics textbook. The chatbot provides book-grounded Q&A within the Docusaurus site using Cohere embeddings, Qdrant Cloud vector storage, and a FastAPI backend. Users can query the entire textbook (Global Mode) or ask questions about selected text (Selected-Text Mode).

**Technical Approach**: Build a three-tier architecture with (1) embedding pipeline for content indexing, (2) stateless FastAPI backend for RAG queries, and (3) embedded React chat widget in Docusaurus frontend.

## Technical Context

**Language/Version**: Python 3.11 (backend), TypeScript/React (frontend)
**Primary Dependencies**: FastAPI, Cohere SDK, Qdrant Client, React
**Storage**: Qdrant Cloud (vector database), No persistent session storage
**Testing**: pytest (backend), Jest (frontend), manual E2E validation
**Target Platform**: Web (Docusaurus static site + API backend)
**Project Type**: Web application (frontend + backend)
**Performance Goals**: <5 seconds response time (95th percentile), 50 concurrent users
**Constraints**: <100KB frontend bundle addition, stateless API, grounded responses only
**Scale/Scope**: ~100 chunks from 12 chapters, 4 modules

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

| Principle | Applicability | Status | Notes |
|-----------|---------------|--------|-------|
| I. Educational Clarity | Applicable | PASS | Chatbot enhances learning through Q&A |
| II. Technical Accuracy | Applicable | PASS | Responses grounded only in verified textbook content |
| III. AI-Native Design | Applicable | PASS | Core RAG functionality leverages modular content |
| IV. RAG Compatibility | Applicable | PASS | Direct implementation of RAG requirement |
| V. Personalization | Applicable | PASS | Persona-aware responses (bonus feature) |
| VI. Multi-Language | N/A | PASS | English-only queries per spec |
| VII. Reusable AI | Applicable | PASS | Enables concept explanation capability |
| VIII. Documentation Standards | Applicable | PASS | API contracts and data models documented |
| IX. Ethics & Integrity | Applicable | PASS | No hallucination policy enforced |
| X. Scope Control | Applicable | PASS | Focused on RAG chatbot only |

**Post-Design Re-Check**: All principles remain compliant after design phase.

## Project Structure

### Documentation (this feature)

```text
specs/005-rag-chatbot-integration/
├── plan.md              # This file
├── research.md          # Cohere/Qdrant integration patterns
├── data-model.md        # Chunk, Query, Response schemas
├── quickstart.md        # Implementation guide
├── contracts/           # API specifications
│   └── rag-api.yaml     # OpenAPI spec for RAG endpoints
├── checklists/
│   └── requirements.md  # Spec quality checklist
└── tasks.md             # Generated by /sp.tasks
```

### Source Code (repository root)

```text
physical-ai-textbook/
├── rag-backend/                    # FastAPI RAG service
│   ├── main_cohere.py              # Main API with Cohere integration
│   ├── embedding_cohere.py         # Cohere embedding service
│   ├── chat_cohere.py              # Cohere Command response generation
│   ├── qdrant_service.py           # Vector database operations
│   ├── models.py                   # Pydantic schemas
│   ├── personas.py                 # Persona definitions
│   └── requirements.txt            # Python dependencies
│
├── docs/                           # Docusaurus site
│   └── src/
│       ├── components/
│       │   └── ChatWidget/         # React chat component
│       │       ├── index.tsx       # Main widget
│       │       ├── ChatPanel.tsx   # Chat UI panel
│       │       └── styles.css      # Widget styles
│       └── theme/
│           └── Root.tsx            # Global widget injection
│
└── scripts/
    └── embed_chapters_cohere.py    # Cohere embedding script
```

**Structure Decision**: Web application pattern with separate backend (FastAPI) and frontend (Docusaurus/React) directories. Backend handles RAG logic; frontend provides embedded chat UI.

## Complexity Tracking

> No constitution violations. Implementation follows standard RAG architecture patterns.

| Aspect | Decision | Rationale |
|--------|----------|-----------|
| Single LLM provider | Cohere | User requirement, consistent embeddings + generation |
| Stateless backend | Selected | Simplifies deployment, meets spec requirements |
| Embedded widget | Selected | Non-intrusive UX, doesn't interfere with reading |

---

## Implementation Phases

### Phase 1: Content Readiness

**Goal**: Ensure all textbook Markdown content is properly structured for RAG ingestion.

**Tasks**:
1. Audit all 12 chapter files for consistent frontmatter (title, module, chapter_id)
2. Verify H2 section boundaries align with semantic chunking targets (200-500 words)
3. Ensure no broken references or incomplete content
4. Validate Markdown syntax compatibility

**Validation**:
- [ ] All chapters have required frontmatter fields
- [ ] Section lengths fall within chunking guidelines
- [ ] No syntax errors in Markdown files

**Deliverable**: Verified, RAG-ready textbook content

---

### Phase 2: Embedding Pipeline

**Goal**: Index all textbook content into Qdrant Cloud using Cohere embeddings.

**Tasks**:
1. Create Cohere embedding service (embed-english-v3.0 model)
2. Implement semantic chunking by H2 sections with metadata preservation
3. Generate embeddings for all chunks (~100 expected)
4. Store vectors in Qdrant Cloud with metadata (chapter, section, URL)
5. Implement re-embedding capability for content updates

**Technical Details**:
- Cohere embed-english-v3.0: 1024-dimension vectors
- Qdrant collection: `textbook_chunks`
- Metadata per chunk: chunk_id, chapter_title, section_title, module, url, text

**Validation**:
- [ ] Cohere API connection verified
- [ ] Qdrant Cloud collection created
- [ ] All chapters successfully embedded
- [ ] Metadata preserved and queryable

**Deliverable**: Indexed textbook content in Qdrant Cloud

---

### Phase 3: Backend RAG Service

**Goal**: Build FastAPI service to handle queries, retrieve chunks, and generate grounded responses.

**Tasks**:
1. Create `/query` endpoint accepting user questions
2. Implement query embedding using Cohere
3. Implement vector similarity search against Qdrant
4. Build response generation using Cohere Command with strict grounding prompt
5. Add source attribution to responses
6. Implement confidence scoring based on similarity thresholds
7. Add error handling and graceful fallbacks

**API Endpoints**:
- `POST /query` - Main RAG query endpoint
- `POST /embed` - Batch embedding endpoint (admin)
- `GET /health` - Health check
- `GET /collection/info` - Collection statistics

**Grounding Prompt Strategy**:
```
You are a helpful assistant for the Physical AI textbook.
Answer ONLY using the provided context from the textbook.
If the context doesn't contain the answer, say so clearly.
Always cite the source chapter and section.
```

**Validation**:
- [ ] Query endpoint returns grounded responses
- [ ] Out-of-scope questions are declined appropriately
- [ ] Source attribution included in all responses
- [ ] Response time < 5 seconds

**Deliverable**: Stateless RAG API service

---

### Phase 4: Query Modes

**Goal**: Support both Global Mode (full book) and Selected-Text Mode (user selection).

**Tasks**:
1. Add `mode` parameter to query endpoint (global/selected)
2. For Global Mode: search entire Qdrant collection
3. For Selected-Text Mode: embed and search only against provided text
4. Implement text length validation (min 10, max 5000 characters)
5. Add fallback suggestion when selected text lacks answer

**Mode Behavior**:
- **Global**: `POST /query { question, mode: "global" }`
- **Selected**: `POST /query { question, mode: "selected", selected_text: "..." }`

**Validation**:
- [ ] Global mode searches full collection
- [ ] Selected mode restricts to provided text
- [ ] Text length limits enforced
- [ ] Clear fallback messaging

**Deliverable**: Mode-aware retrieval system

---

### Phase 5: Frontend Integration

**Goal**: Embed minimal chat widget in Docusaurus without disrupting reading experience.

**Tasks**:
1. Create React ChatWidget component
2. Implement collapsible chat panel (bottom-right corner)
3. Add mode toggle (Global/Selected-Text)
4. Implement text selection detection for Selected-Text mode
5. Display source references as clickable links
6. Style to match Teal & Navy theme
7. Ensure < 100KB bundle size addition

**UI Components**:
- Floating chat button (collapsed state)
- Chat panel with message history
- Mode toggle switch
- Source reference links
- Loading/error states

**Validation**:
- [ ] Widget renders on all pages
- [ ] Chat panel opens/closes smoothly
- [ ] Mode toggle functions correctly
- [ ] Text selection triggers Selected-Text mode
- [ ] Source links navigate to correct sections
- [ ] Bundle size within limit

**Deliverable**: Functional in-book chatbot UI

---

### Phase 6: Quality and Safety

**Goal**: Validate grounding, handle edge cases, and secure API keys.

**Tasks**:
1. Test grounding with out-of-scope questions
2. Validate confidence thresholds (0.7 default)
3. Test edge cases (empty input, very long input, non-English)
4. Secure API keys (environment variables, not in frontend)
5. Implement rate limiting (if needed)
6. Add CORS configuration for frontend domain

**Security Measures**:
- API keys in environment variables only
- Input validation and sanitization
- CORS restricted to allowed origins
- No sensitive data in frontend bundle

**Validation**:
- [ ] Out-of-scope questions handled correctly
- [ ] Edge cases produce appropriate responses
- [ ] No API keys exposed in frontend
- [ ] CORS configured correctly
- [ ] Rate limiting functional (if implemented)

**Deliverable**: Secure and reliable chatbot system

---

## Risk Mitigation

| Risk | Mitigation Strategy |
|------|---------------------|
| Cohere API rate limits | Implement request caching, consider batching |
| Qdrant free tier limits | Monitor usage, optimize chunk count (~100) |
| Poor retrieval quality | Tune similarity threshold, improve chunking |
| Hallucination despite RAG | Strict grounding prompt, confidence thresholds |
| Frontend bundle bloat | Code splitting, lazy loading, minification |
| API key exposure | Environment variables, backend-only secrets |

---

## Dependencies

| Dependency | Purpose | Version |
|------------|---------|---------|
| Cohere SDK | Embeddings + Generation | Latest |
| Qdrant Client | Vector storage | Latest |
| FastAPI | Backend framework | 0.100+ |
| React | Frontend widget | 18.x |
| python-dotenv | Environment config | Latest |

---

## RAG Chatbot Plan Completion Criteria

The RAG chatbot implementation is complete when:

1. **Content Indexed**: All 12 textbook chapters are embedded in Qdrant Cloud with Cohere embeddings
2. **Backend Operational**: FastAPI service handles queries with <5 second response time
3. **Grounding Verified**: 95% of out-of-scope questions are correctly declined
4. **Modes Working**: Both Global and Selected-Text modes function correctly
5. **Frontend Integrated**: Chat widget embedded in Docusaurus with <100KB addition
6. **Sources Attributed**: 100% of responses include clickable source references
7. **Security Validated**: No API keys exposed, CORS configured, inputs sanitized
8. **Availability**: Chatbot operational on deployed Vercel site

---

## Next Steps

Run `/sp.tasks` to generate detailed implementation tasks from this plan.
